{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3#!/usr/ \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 17 18:10:43 2018\n",
    "\n",
    "@author: jacobjohn\n",
    "\n",
    "A) Consider the following two sentences\n",
    "1. Term frequency matrix is important for ranking docs.\n",
    "2. TFIDF is more important than Term frequency matrix for the same.\n",
    "\n",
    "    i) Find TF MATRIX, IDF values of each term and finally TF*IDF MATRIX.\n",
    "    ii) Find cosine similarity also.\n",
    "\n",
    "\n",
    "B) Implement PAGE RANK ALGORITHM. Take input for adjacency matrix (no need to visualise the directed graph), \n",
    "   find stochastic matrix, find transpose of it. Consider dumping factor 0.7. Consider initial P values as all 1s.  \n",
    "   You can consider 5 nodes. Calculate page rank until 2 iterations and display the ranks.\n",
    "   \n",
    "C) Implement Ellias Gamma, Ellias Delta and Golomb coding\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence is:  Term frequency matrix is important for ranking docs.\n",
      "TF-IDF Matrix: \n",
      "[0.0, 0.0, 0.0, 1.0, 1.0, 1.6931471805599454, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.6931471805599454]\n",
      "\n",
      "\n",
      "Sentence is: TFIDF is more important than Term frequency matrix for the same.\n",
      "TF-IDF Matrix: \n",
      "[1.6931471805599454, 1.6931471805599454, 1.6931471805599454, 1.0, 1.0, 0.0, 1.0, 1.6931471805599454, 1.6931471805599454, 1.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import string\n",
    "import math\n",
    " \n",
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    " \n",
    "document_0 = \"Term frequency matrix is important for ranking docs.\"\n",
    "document_1 = \"TFIDF is more important than Term frequency matrix for the same.\"\n",
    " \n",
    "all_documents = [document_0, document_1]\n",
    " \n",
    "def term_frequency(term, tokenized_document):\n",
    "    return tokenized_document.count(term)\n",
    " \n",
    "def sublinear_term_frequency(term, tokenized_document):\n",
    "    count = tokenized_document.count(term)\n",
    "    if count == 0:\n",
    "        return 0\n",
    "    return 1 + math.log(count)\n",
    " \n",
    "def augmented_term_frequency(term, tokenized_document):\n",
    "    max_count = max([term_frequency(t, tokenized_document) for t in tokenized_document])\n",
    "    return (0.5 + ((0.5 * term_frequency(term, tokenized_document))/max_count))\n",
    " \n",
    "def inverse_document_frequencies(tokenized_documents):\n",
    "    idf_values = {}\n",
    "    all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "    for tkn in all_tokens_set:\n",
    "        contains_token = map(lambda doc: tkn in doc, tokenized_documents)\n",
    "        idf_values[tkn] = 1 + math.log(len(tokenized_documents)/(sum(contains_token)))\n",
    "    return idf_values\n",
    " \n",
    "def tfidf(documents):\n",
    "    tokenized_documents = [tokenize(d) for d in documents]\n",
    "    idf = inverse_document_frequencies(tokenized_documents)\n",
    "    tfidf_documents = []\n",
    "    for document in tokenized_documents:\n",
    "        doc_tfidf = []\n",
    "        for term in idf.keys():\n",
    "            tf = sublinear_term_frequency(term, document)\n",
    "            doc_tfidf.append(tf * idf[term])\n",
    "        tfidf_documents.append(doc_tfidf)\n",
    "    return tfidf_documents\n",
    " \n",
    "tfidf_representation = tfidf(all_documents)\n",
    "print(\"Sentence is: \",document_0)\n",
    "print(\"TF-IDF Matrix: \")\n",
    "print(tfidf_representation[0])\n",
    "print(\"\\n\")\n",
    "print(\"Sentence is:\", document_1)\n",
    "print(\"TF-IDF Matrix: \")\n",
    "print(tfidf_representation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence is:  Term frequency matrix is important for ranking docs.\n",
      "[0.4942890846583352, 0.29193509597604356, 0.29193509597604356, 0.29193509597604356, 0.29193509597604356, 0.29193509597604356, 0.0, 0.4942890846583352, 0.0, 0.29193509597604356, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Sentence is: TFIDF is more important than Term frequency matrix for the same.\n",
      "[0.0, 0.22176418069574952, 0.22176418069574952, 0.22176418069574952, 0.22176418069574952, 0.22176418069574952, 0.37547939729419455, 0.0, 0.37547939729419455, 0.22176418069574952, 0.37547939729419455, 0.37547939729419455, 0.37547939729419455]\n"
     ]
    }
   ],
   "source": [
    "#in Scikit-Learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)\n",
    "sklearn_representation = sklearn_tfidf.fit_transform(all_documents)\n",
    "print(\"Sentence is: \",document_0)\n",
    "print(sklearn_representation.toarray()[0].tolist())\n",
    "print(\"\\n\")\n",
    "print(\"Sentence is:\", document_1)\n",
    "print(sklearn_representation.toarray()[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1.0000000000000002, 0, 0), (1.0000000000000002, 1, 1))\n",
      "((0.9999999999999998, 1, 1), (1.0000000000000002, 0, 0))\n",
      "((0.3884444842527737, 1, 0), (0.38844448425277384, 1, 0))\n",
      "((0.3884444842527737, 0, 1), (0.38844448425277384, 0, 1))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cosine Similairty\n",
    "\"\"\"\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = sum(p*q for p,q in zip(vector1, vector2))\n",
    "    magnitude = math.sqrt(sum([val**2 for val in vector1])) * math.sqrt(sum([val**2 for val in vector2]))\n",
    "    if not magnitude:\n",
    "        return 0\n",
    "    return dot_product/magnitude\n",
    "\n",
    "tfidf_representation = tfidf(all_documents)\n",
    "our_tfidf_comparisons = []\n",
    "for count_0, doc_0 in enumerate(tfidf_representation):\n",
    "    for count_1, doc_1 in enumerate(tfidf_representation):\n",
    "        our_tfidf_comparisons.append((cosine_similarity(doc_0, doc_1), count_0, count_1))\n",
    "\n",
    "skl_tfidf_comparisons = []\n",
    "for count_0, doc_0 in enumerate(sklearn_representation.toarray()):\n",
    "    for count_1, doc_1 in enumerate(sklearn_representation.toarray()):\n",
    "        skl_tfidf_comparisons.append((cosine_similarity(doc_0, doc_1), count_0, count_1))\n",
    "\n",
    "for x in zip(sorted(our_tfidf_comparisons, reverse = True), sorted(skl_tfidf_comparisons, reverse = True)):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 1, 0, 0]\n",
      " [0, 0, 0, 0, 0]\n",
      " [1, 1, 0, 0, 1]\n",
      " [0, 0, 0, 0, 1]\n",
      " [0, 0, 0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Page Rank\n",
    "\"\"\"\n",
    "\n",
    "#calculating page rank of a given graph\n",
    "import igraph\n",
    "from numpy import *\n",
    "\n",
    "gd = igraph.Graph(directed=True)\n",
    "gd.add_vertices(5) \n",
    "gd.add_edges([(0,1),(0,2),(2,0),(2,1),(2,4),(3,4),(4,3)]) \n",
    "result = gd.get_adjacency()\n",
    "\n",
    "print(gd.get_adjacency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic matrix is: \n",
      "[[0, 0.5, 0.5, 0, 0]\n",
      " [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      " [0.3333333333333333, 0.3333333333333333, 0, 0, 0.3333333333333333]\n",
      " [0, 0, 0, 0, 1.0]\n",
      " [0, 0, 0, 1.0, 0]]\n"
     ]
    }
   ],
   "source": [
    "#Stochastic matrix calculation\n",
    "stoc = result\n",
    "sum = [0,0,0,0,0]\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        sum[i] += result[i,j]\n",
    "        \n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if sum[i] == 0:\n",
    "            stoc[i,j] = 1/5\n",
    "        else:\n",
    "            if stoc[i,j] > 0:\n",
    "                stoc[i,j] = stoc[i,j]/sum[i]\n",
    "print(\"Stochastic matrix is: \")\n",
    "print(stoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose is: \n",
      "[[0, 0.2, 0.3333333333333333, 0, 0], [0.5, 0.2, 0.3333333333333333, 0, 0], [0.5, 0.2, 0, 0, 0], [0, 0.2, 0, 0, 1.0], [0, 0.2, 0.3333333333333333, 1.0, 0]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating transpose\n",
    "trans = [[stoc[j][i] for j in range(5)] for i in range(5)]\n",
    "\n",
    "print(\"Transpose is: \")\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page rank of 1 is:  0.2\n",
      "Page rank of 2 is:  0.21276595744728455\n",
      "Page rank of 3 is:  0.22000000000000003\n",
      "Page rank of 4 is:  0.26\n",
      "Page rank of 5 is:  0.2\n",
      "\n",
      "Ranks are as follows: \n",
      "P4 >> P3 >> P2 >> P1 >> P5 >> "
     ]
    }
   ],
   "source": [
    "#Page Rank Calculation\n",
    "d = 0.7\n",
    "n = 5\n",
    "m = 5\n",
    "E = [1] * n\n",
    "rank = [1] * n\n",
    "for i in range(n):\n",
    "    E[i] = [1] * m\n",
    "\n",
    "for it in range(2):\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            rank[j] = ((E[i][j])/n)+((1-d)*trans[i][j])*rank[j]\n",
    "\n",
    "for index in range(len(rank)):\n",
    "    print(\"Page rank of\",index+1,\"is: \",rank[index])\n",
    "\n",
    "sort_rank = [i[0] for i in sorted(enumerate(rank), key=lambda x:x[1], reverse = True)]\n",
    "\n",
    "print(\"\\nRanks are as follows: \")\n",
    "for index in sort_rank:\n",
    "    print(\"P\",index+1,\" >> \",end = \"\",sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Num: Gamma      : Delta      : Goloumb   \n",
      "    0: 0          : 0          : 00        \n",
      "    1: 100        : 1000       : 01        \n",
      "    2: 1100       : 11000      : 010       \n",
      "    3: 1101       : 11001      : 100       \n",
      "    4: 11100      : 11010      : 101       \n",
      "    5: 11101      : 11011      : 1010      \n",
      "    6: 111010     : 110110     : 1100      \n",
      "    7: 111011     : 110111     : 1101      \n",
      "    8: 111100     : 111000     : 11010     \n",
      "    9: 111101     : 111001     : 11100     \n",
      "   10: 1111010    : 1110010    : 11101     \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Implement Ellias Gamma, Ellias Delta and Golomb coding\n",
    "'''\n",
    "\n",
    "from math import log,ceil\n",
    "\n",
    "log2 = lambda x: log(x,2)\n",
    "\n",
    "def binary(x, l = 1):\n",
    "\tfmt = '{0:0%db}'%1\n",
    "\treturn fmt.format(x)\n",
    "\n",
    "def unary(x):\n",
    "\treturn x*'1'+'0'\n",
    "\n",
    "def elias_generic(lencoding, x):\n",
    "\tif x == 0: return '0'\n",
    "\tl = 1+int(log2(x))\n",
    "\ta = x - 2**(int(log2(x)))\n",
    "\tk = int(log2(x))\n",
    "\treturn lencoding(l) + binary(a,k)\n",
    "\n",
    "def golomb(b, x):\n",
    "\tq = int((x) / b)\n",
    "\tr = int((x) % b)\n",
    "\tl = int(ceil(log2(b)))\n",
    "\t#print(q,r,l)\n",
    "\treturn unary(q) + binary(r, l)\n",
    "\n",
    "def elias_gamma(x):\n",
    "    return elias_generic(unary, x)\n",
    "\n",
    "def elias_delta(x):\n",
    "    return elias_generic(elias_gamma,x)\n",
    "\n",
    "print(\"%5s: %-10s : %-10s : %-10s\" %\n",
    "      (\"Num\", \"Gamma\", \"Delta\", \"Goloumb\"))\n",
    "for i in range(11):\n",
    "\tprint(\"%5d: %-10s : %-10s : %-10s\" %\n",
    "\t(i,elias_gamma(i),elias_delta(i), golomb(3,i)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
