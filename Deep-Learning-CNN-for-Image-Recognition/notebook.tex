
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{02\_ConvolutionalNeuralNetwork-OCR}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Convolutional Neural Network -
OCR}\label{convolutional-neural-network---ocr}

by Gaetano Bonofiglio, Veronica Iovinella

\subsection{Introduction}\label{introduction}

The previous notebook showed that a simple linear model had about 91\%
classification accuracy for recognizing hand-written digits in the MNIST
data-set.

In this notebook we will implement a simple \textbf{Convolutional Neural
Network} in \(TensorFlow\) which has a classification accuracy of about
99\%, or more.

Convolutional Networks work by moving small filters across the input
image. This means the filters are re-used for recognizing patterns
throughout the entire input image, making the Convolutional Networks
much more powerful than Fully-Connected networks with the same number of
variables. A Convolutional Network is also faster to train.

\subsection{Flowchart}\label{flowchart}

The following chart shows roughly how the data flows in the
Convolutional Neural Network that is implemented below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{Image}
        \PY{n}{Image}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{images/02\PYZus{}flowchart.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\texttt{\color{outcolor}Out[{\color{outcolor}1}]:}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_1_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    The input image is processed in the first convolutional layer using the
filter-weights. This results in 16 new images, one for each filter in
the convolutional layer. The resulting images are also down-sampled from
28x28 to 14x14 pixels.

These 16 smaller images are then processed in the second convolutional
layer. There are 36 output channels in this output layer, so there are a
total of 16 x 36 = 576 filters in the second convolutional layer,
because we need filter-weights for each of these 16 channels, and we
need filter-weights for each output channel of this layer. The resulting
images are down-sampled again to 7x7 pixels.

The output of the second convolutional layer is 36 images of 7x7 pixels
each. These are then flattened to a single vector of length 7 x 7 x 36 =
1764, which is used as the input to a fully-connected layer with 128
neurons. This feeds into another fully-connected layer with 10 neurons,
one for each of the classes, which is used to determine the class of the
image (the number depicted in the image), as in the previous notebook.

The convolutional filters are initially chosen at random, so the
classification is done randomly. The error between the predicted and
true class of the input image is measured again as cross-entropy. The
optimizer then automatically propagates this error back through the
Convolutional Network using the chain-rule of differentiation and
updates the filter-weights so as to improve the classification error.
This is done iteratively thousands of times until the classification
error is sufficiently low.

These particular filter-weights and intermediate images are the results
of one optimization run and may look different if you re-run this
notebook.

Note that the computation in \(TensorFlow\) is actually done on a batch
of images instead of a single image, which makes the computation more
efficient.

\subsection{Convolutional Layer}\label{convolutional-layer}

The following chart shows the basic idea of processing an image in the
first convolutional layer. The input image depicts the number 7 and four
copies of the image are shown here, so we can see more clearly how the
filter is being moved to different positions of the image. For each
position of the filter, the dot-product is being calculated between the
filter and the image pixels under the filter, which results in a single
pixel in the output image. So moving the filter across the entire input
image results in a new image being generated.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{Image}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{images/02\PYZus{}convolution.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

\texttt{\color{outcolor}Out[{\color{outcolor}2}]:}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_3_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    The red filter-weights means that the filter has a positive reaction to
black pixels in the input image, while blue pixels means the filter has
a negative reaction to black pixels.

In this case it appears that \textbf{the filter recognizes the
horizontal line} of the 7-digit, as can be seen from its stronger
reaction to that line in the output image.

The step-size for moving the filter across the input is called the
stride. There is a stride for moving the filter horizontally (x-axis)
and another stride for moving vertically (y-axis).

In the source-code below, the stride is set to 1 in both directions,
which means the filter starts in the upper left corner of the input
image and is being moved 1 pixel to the right in each step. When the
filter reaches the end of the image to the right, then the filter is
moved back to the left side and 1 pixel down the image. This continues
until the filter has reached the lower right corner of the input image
and the entire output image has been generated.

When the filter reaches the end of the right-side as well as the bottom
of the input image, then it can be padded with zeroes (white pixels).
This causes the output image to be of the exact same dimension as the
input image.

Furthermore, the output of the convolution may be passed through a
so-called Rectified Linear Unit (ReLU), which merely ensures that the
output is positive because negative values are set to zero. The output
may also be down-sampled by so-called max-pooling, which considers small
windows of 2x2 pixels and only keeps the largest of those pixels. This
halves the resolution of the input image e.g. from 28x28 to 14x14
pixels.

\subsection{Imports}\label{imports}

As in the previous notebook, helper functions are in \url{util.py}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{time}
        \PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k}{import} \PY{n}{timedelta}
        
        \PY{k+kn}{from} \PY{n+nn}{util} \PY{k}{import} \PY{n}{Util}
        \PY{n}{u} \PY{o}{=} \PY{n}{Util}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{tf}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}2}]:} '1.10.0'
\end{Verbatim}
            
    \subsection{Configuration of Neural
Network}\label{configuration-of-neural-network}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} Convolutional Layer 1.}
        \PY{n}{filter\PYZus{}size1} \PY{o}{=} \PY{l+m+mi}{5}          \PY{c+c1}{\PYZsh{} Convolution filters are 5 x 5 pixels.}
        \PY{n}{num\PYZus{}filters1} \PY{o}{=} \PY{l+m+mi}{16}         \PY{c+c1}{\PYZsh{} There are 16 of these filters.}
        
        \PY{c+c1}{\PYZsh{} Convolutional Layer 2.}
        \PY{n}{filter\PYZus{}size2} \PY{o}{=} \PY{l+m+mi}{5}          \PY{c+c1}{\PYZsh{} Convolution filters are 5 x 5 pixels.}
        \PY{n}{num\PYZus{}filters2} \PY{o}{=} \PY{l+m+mi}{36}         \PY{c+c1}{\PYZsh{} There are 36 of these filters.}
        
        \PY{c+c1}{\PYZsh{} Fully\PYZhy{}connected layer.}
        \PY{n}{fc\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{128}             \PY{c+c1}{\PYZsh{} Number of neurons in fully\PYZhy{}connected layer.}
\end{Verbatim}


    \subsection{Data Load}\label{data-load}

We load the same dataset as the previous notebook.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{examples}\PY{n+nn}{.}\PY{n+nn}{tutorials}\PY{n+nn}{.}\PY{n+nn}{mnist} \PY{k}{import} \PY{n}{input\PYZus{}data}
        \PY{n}{data} \PY{o}{=} \PY{n}{input\PYZus{}data}\PY{o}{.}\PY{n}{read\PYZus{}data\PYZus{}sets}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{data/MNIST/}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{one\PYZus{}hot}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:tensorflow:From <ipython-input-4-37adf088ce13>:2: read\_data\_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe\_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: \_internal\_retry.<locals>.wrap.<locals>.wrapped\_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please use urllib or similar directly.
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract\_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting data/MNIST/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract\_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting data/MNIST/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense\_to\_one\_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one\_hot on tensors.
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting data/MNIST/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting data/MNIST/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.\_\_init\_\_ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Size of}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{} Training\PYZhy{}set:}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{labels}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{} Test\PYZhy{}set:}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{test}\PY{o}{.}\PY{n}{labels}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{} Validation\PYZhy{}set:}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{validation}\PY{o}{.}\PY{n}{labels}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Size of
- Training-set:		55000
- Test-set:		10000
- Validation-set:	5000

    \end{Verbatim}

    As we did before, we need the number corrisponding to the class-labels,
that are One-Hot encoded

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{data}\PY{o}{.}\PY{n}{test}\PY{o}{.}\PY{n}{cls} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{test}\PY{o}{.}\PY{n}{labels}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Data Dimensions}\label{data-dimensions}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} We know that MNIST images are 28 pixels in each dimension.}
        \PY{n}{img\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{28}
        
        \PY{c+c1}{\PYZsh{} Images are stored in one\PYZhy{}dimensional arrays of this length.}
        \PY{n}{img\PYZus{}size\PYZus{}flat} \PY{o}{=} \PY{n}{img\PYZus{}size} \PY{o}{*} \PY{n}{img\PYZus{}size}
        
        \PY{c+c1}{\PYZsh{} Tuple with height and width of images used to reshape arrays.}
        \PY{n}{img\PYZus{}shape} \PY{o}{=} \PY{p}{(}\PY{n}{img\PYZus{}size}\PY{p}{,} \PY{n}{img\PYZus{}size}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Number of colour channels for the images: 1 channel for gray\PYZhy{}scale.}
        \PY{n}{num\PYZus{}channels} \PY{o}{=} \PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{} Number of classes, one class for each of 10 digits.}
        \PY{n}{num\PYZus{}classes} \PY{o}{=} \PY{l+m+mi}{10}
\end{Verbatim}


    \subsubsection{Helper-function for plotting
images}\label{helper-function-for-plotting-images}

Function used to plot 9 images in a 3x3 grid, and writing the true and
predicted classes below each image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}images}\PY{p}{(}\PY{n}{images}\PY{p}{,} \PY{n}{cls\PYZus{}true}\PY{p}{,} \PY{n}{cls\PYZus{}pred}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:} 
            \PY{n}{u}\PY{o}{.}\PY{n}{plot\PYZus{}images}\PY{p}{(}\PY{n}{images}\PY{o}{=}\PY{n}{images}\PY{p}{,} \PY{n}{cls\PYZus{}true}\PY{o}{=}\PY{n}{cls\PYZus{}true}\PY{p}{,} \PY{n}{cls\PYZus{}pred}\PY{o}{=}\PY{n}{cls\PYZus{}pred}\PY{p}{,} \PY{n}{img\PYZus{}size}\PY{o}{=}\PY{n}{img\PYZus{}size}\PY{p}{,} \PY{n}{img\PYZus{}shape}\PY{o}{=}\PY{n}{img\PYZus{}shape}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Plot a few images to see if data is
correct}\label{plot-a-few-images-to-see-if-data-is-correct}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Get the first images from the test\PYZhy{}set.}
         \PY{n}{images} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{test}\PY{o}{.}\PY{n}{images}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{9}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Get the true classes for those images.}
         \PY{n}{cls\PYZus{}true} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{test}\PY{o}{.}\PY{n}{cls}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{9}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Plot the images and labels using our helper\PYZhy{}function above.}
         \PY{n}{plot\PYZus{}images}\PY{p}{(}\PY{n}{images}\PY{o}{=}\PY{n}{images}\PY{p}{,} \PY{n}{cls\PYZus{}true}\PY{o}{=}\PY{n}{cls\PYZus{}true}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{TensorFlow Graph}\label{tensorflow-graph}

Aside from the convolutional part, the structure of the \(TensorFlow\)
graph is the same as the previous notebook, consisting of the following
parts: - Placeholder variables used for inputting data to the graph. -
Variables that are going to be optimized so as to make the convolutional
network perform better. - The mathematical formulas for the
convolutional network. - A cost measure that can be used to guide the
optimization of the variables. - An optimization method which updates
the variables.

\subsubsection{Helper-functions for creating new
variables}\label{helper-functions-for-creating-new-variables}

Functions for creating new \(TensorFlow\) variables in the given shape
and initializing them with random values. Note that the initialization
is not actually done at this point, it is merely being defined in the
\(TensorFlow\) graph. In the previous notebook we used zeros instead of
random values.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k}{def} \PY{n+nf}{new\PYZus{}weights}\PY{p}{(}\PY{n}{shape}\PY{p}{)}\PY{p}{:}
             \PY{k}{return} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{n}{shape}\PY{p}{,} \PY{n}{stddev}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{new\PYZus{}biases}\PY{p}{(}\PY{n}{length}\PY{p}{)}\PY{p}{:}
             \PY{k}{return} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{constant}\PY{p}{(}\PY{l+m+mf}{0.05}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{n}{length}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Helper-function for creating a new Convolutional
Layer}\label{helper-function-for-creating-a-new-convolutional-layer}

This function creates a new convolutional layer in the computational
graph for \(TensorFlow\). Nothing is actually calculated here, we are
just adding the mathematical formulas to the TensorFlow graph.

It is assumed that the input is a 4-dim \emph{tensor} with the following
dimensions: - Image number. - Y-axis of each image. - X-axis of each
image. - Channels of each image.

Note that the input channels may either be colour-channels, or it may be
filter-channels if the input is produced from a previous convolutional
layer.

The output is another 4-dim \emph{tensor} with the following dimensions:
- Image number, same as input. - Y-axis of each image. If 2x2 pooling is
used, then the height and width of the input images is divided by 2. -
X-axis of each image. As above. - Channels produced by the convolutional
filters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k}{def} \PY{n+nf}{new\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,}              \PY{c+c1}{\PYZsh{} The previous layer.}
                            \PY{n}{num\PYZus{}input\PYZus{}channels}\PY{p}{,} \PY{c+c1}{\PYZsh{} Num. channels in prev. layer.}
                            \PY{n}{filter\PYZus{}size}\PY{p}{,}        \PY{c+c1}{\PYZsh{} Width and height of each filter.}
                            \PY{n}{num\PYZus{}filters}\PY{p}{,}        \PY{c+c1}{\PYZsh{} Number of filters.}
                            \PY{n}{use\PYZus{}pooling}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:}  \PY{c+c1}{\PYZsh{} Use 2x2 max\PYZhy{}pooling.}
         
             \PY{c+c1}{\PYZsh{} Shape of the filter\PYZhy{}weights for the convolution.}
             \PY{c+c1}{\PYZsh{} This format is determined by the TensorFlow API.}
             \PY{n}{shape} \PY{o}{=} \PY{p}{[}\PY{n}{filter\PYZus{}size}\PY{p}{,} \PY{n}{filter\PYZus{}size}\PY{p}{,} \PY{n}{num\PYZus{}input\PYZus{}channels}\PY{p}{,} \PY{n}{num\PYZus{}filters}\PY{p}{]}
         
             \PY{c+c1}{\PYZsh{} Create new weights aka. filters with the given shape.}
             \PY{n}{weights} \PY{o}{=} \PY{n}{new\PYZus{}weights}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{n}{shape}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Create new biases, one for each filter.}
             \PY{n}{biases} \PY{o}{=} \PY{n}{new\PYZus{}biases}\PY{p}{(}\PY{n}{length}\PY{o}{=}\PY{n}{num\PYZus{}filters}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Create the TensorFlow operation for convolution.}
             \PY{c+c1}{\PYZsh{} Note the strides are set to 1 in all dimensions.}
             \PY{c+c1}{\PYZsh{} The first and last stride must always be 1,}
             \PY{c+c1}{\PYZsh{} because the first is for the image\PYZhy{}number and}
             \PY{c+c1}{\PYZsh{} the last is for the input\PYZhy{}channel.}
             \PY{c+c1}{\PYZsh{} But e.g. strides=[1, 2, 2, 1] would mean that the filter}
             \PY{c+c1}{\PYZsh{} is moved 2 pixels across the x\PYZhy{} and y\PYZhy{}axis of the image.}
             \PY{c+c1}{\PYZsh{} The padding is set to \PYZsq{}SAME\PYZsq{} which means the input image}
             \PY{c+c1}{\PYZsh{} is padded with zeroes so the size of the output is the same.}
             \PY{n}{layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n+nb}{input}\PY{o}{=}\PY{n+nb}{input}\PY{p}{,}
                                  \PY{n+nb}{filter}\PY{o}{=}\PY{n}{weights}\PY{p}{,}
                                  \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                  \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Add the biases to the results of the convolution.}
             \PY{c+c1}{\PYZsh{} A bias\PYZhy{}value is added to each filter\PYZhy{}channel.}
             \PY{n}{layer} \PY{o}{+}\PY{o}{=} \PY{n}{biases}
         
             \PY{c+c1}{\PYZsh{} Use pooling to down\PYZhy{}sample the image resolution?}
             \PY{k}{if} \PY{n}{use\PYZus{}pooling}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} This is 2x2 max\PYZhy{}pooling, which means that we}
                 \PY{c+c1}{\PYZsh{} consider 2x2 windows and select the largest value}
                 \PY{c+c1}{\PYZsh{} in each window. Then we move 2 pixels to the next window.}
                 \PY{n}{layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{max\PYZus{}pool}\PY{p}{(}\PY{n}{value}\PY{o}{=}\PY{n}{layer}\PY{p}{,}
                                        \PY{n}{ksize}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                        \PY{n}{strides}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                                        \PY{n}{padding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SAME}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Rectified Linear Unit (ReLU).}
             \PY{c+c1}{\PYZsh{} It calculates max(x, 0) for each input pixel x.}
             \PY{c+c1}{\PYZsh{} This adds some non\PYZhy{}linearity to the formula and allows us}
             \PY{c+c1}{\PYZsh{} to learn more complicated functions.}
             \PY{n}{layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{layer}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Note that ReLU is normally executed before the pooling,}
             \PY{c+c1}{\PYZsh{} but since relu(max\PYZus{}pool(x)) == max\PYZus{}pool(relu(x)) we can}
             \PY{c+c1}{\PYZsh{} save 75\PYZpc{} of the relu\PYZhy{}operations by max\PYZhy{}pooling first.}
         
             \PY{c+c1}{\PYZsh{} We return both the resulting layer and the filter\PYZhy{}weights}
             \PY{c+c1}{\PYZsh{} because we will plot the weights later.}
             \PY{k}{return} \PY{n}{layer}\PY{p}{,} \PY{n}{weights}
\end{Verbatim}


    \subsubsection{Helper-function for flattening a
layer}\label{helper-function-for-flattening-a-layer}

A convolutional layer produces an output tensor with 4 dimensions. We
will add fully-connected layers after the convolution layers, so we need
to reduce the 4-dim tensor to 2-dim which can be used as input to the
fully-connected layer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k}{def} \PY{n+nf}{flatten\PYZus{}layer}\PY{p}{(}\PY{n}{layer}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Get the shape of the input layer.}
             \PY{n}{layer\PYZus{}shape} \PY{o}{=} \PY{n}{layer}\PY{o}{.}\PY{n}{get\PYZus{}shape}\PY{p}{(}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} The shape of the input layer is assumed to be:}
             \PY{c+c1}{\PYZsh{} layer\PYZus{}shape == [num\PYZus{}images, img\PYZus{}height, img\PYZus{}width, num\PYZus{}channels]}
         
             \PY{c+c1}{\PYZsh{} The number of features is: img\PYZus{}height * img\PYZus{}width * num\PYZus{}channels}
             \PY{c+c1}{\PYZsh{} We can use a function from TensorFlow to calculate this.}
             \PY{n}{num\PYZus{}features} \PY{o}{=} \PY{n}{layer\PYZus{}shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{l+m+mi}{4}\PY{p}{]}\PY{o}{.}\PY{n}{num\PYZus{}elements}\PY{p}{(}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Reshape the layer to [num\PYZus{}images, num\PYZus{}features].}
             \PY{c+c1}{\PYZsh{} Note that we just set the size of the second dimension}
             \PY{c+c1}{\PYZsh{} to num\PYZus{}features and the size of the first dimension to \PYZhy{}1}
             \PY{c+c1}{\PYZsh{} which means the size in that dimension is calculated}
             \PY{c+c1}{\PYZsh{} so the total size of the tensor is unchanged from the reshaping.}
             \PY{n}{layer\PYZus{}flat} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{layer}\PY{p}{,} \PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}features}\PY{p}{]}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} The shape of the flattened layer is now:}
             \PY{c+c1}{\PYZsh{} [num\PYZus{}images, img\PYZus{}height * img\PYZus{}width * num\PYZus{}channels]}
         
             \PY{c+c1}{\PYZsh{} Return both the flattened layer and the number of features.}
             \PY{k}{return} \PY{n}{layer\PYZus{}flat}\PY{p}{,} \PY{n}{num\PYZus{}features}
\end{Verbatim}


    \subsubsection{Helper-function for creating a new Fully-Connected
Layer}\label{helper-function-for-creating-a-new-fully-connected-layer}

This function creates a new fully-connected layer in the computational
graph for \(TensorFlow\). Nothing is actually calculated here, we are
just adding the mathematical formulas to the TensorFlow graph. It is
assumed that the input is a 2-dim tensor of shape {[}num\_images,
num\_inputs{]}. The output is a 2-dim tensor of shape {[}num\_images,
num\_outputs{]}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{k}{def} \PY{n+nf}{new\PYZus{}fc\PYZus{}layer}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,}          \PY{c+c1}{\PYZsh{} The previous layer.}
                          \PY{n}{num\PYZus{}inputs}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Num. inputs from prev. layer.}
                          \PY{n}{num\PYZus{}outputs}\PY{p}{,}    \PY{c+c1}{\PYZsh{} Num. outputs.}
                          \PY{n}{use\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:} \PY{c+c1}{\PYZsh{} Use Rectified Linear Unit (ReLU)?}
         
             \PY{c+c1}{\PYZsh{} Create new weights and biases.}
             \PY{n}{weights} \PY{o}{=} \PY{n}{new\PYZus{}weights}\PY{p}{(}\PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{n}{num\PYZus{}inputs}\PY{p}{,} \PY{n}{num\PYZus{}outputs}\PY{p}{]}\PY{p}{)}
             \PY{n}{biases} \PY{o}{=} \PY{n}{new\PYZus{}biases}\PY{p}{(}\PY{n}{length}\PY{o}{=}\PY{n}{num\PYZus{}outputs}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Calculate the layer as the matrix multiplication of}
             \PY{c+c1}{\PYZsh{} the input and weights, and then add the bias\PYZhy{}values.}
             \PY{n}{layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{n}{weights}\PY{p}{)} \PY{o}{+} \PY{n}{biases}
         
             \PY{c+c1}{\PYZsh{} Use ReLU?}
             \PY{k}{if} \PY{n}{use\PYZus{}relu}\PY{p}{:}
                 \PY{n}{layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{layer}\PY{p}{)}
         
             \PY{k}{return} \PY{n}{layer}
\end{Verbatim}


    \subsubsection{Placeholder variables}\label{placeholder-variables}

Placeholder variables serve as the input to the \(TensorFlow\)
computational graph that we may change each time we execute the graph
(feeding).

First we define the placeholder variable for the input images. This
allows us to change the images that are input to the \(TensorFlow\)
graph. This is a so-called tensor, which just means that it is a
multi-dimensional vector or matrix. The data-type is set to float32 and
the shape is set to {[}None, img\_size\_flat{]}, where None means that
the tensor may hold an arbitrary number of images with each image being
a vector of length img\_size\_flat.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{x} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{n}{img\PYZus{}size\PYZus{}flat}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    The convolutional layers expect x to be encoded as a 4-dim tensor so we
have to reshape it so its shape is instead {[}num\_images, img\_height,
img\_width, num\_channels{]}. Note that img\_height == img\_width ==
img\_size and num\_images can be inferred automatically by using -1 for
the size of the first dimension. So the reshape operation is:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{x\PYZus{}image} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{img\PYZus{}size}\PY{p}{,} \PY{n}{img\PYZus{}size}\PY{p}{,} \PY{n}{num\PYZus{}channels}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    Next we have the placeholder variable for the true labels associated
with the images that were input in the placeholder variable x. The shape
of this placeholder variable is {[}None, num\_classes{]} which means it
may hold an arbitrary number of labels and each label is a vector of
length num\_classes which is 10 in this case.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{y\PYZus{}true} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}true}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    We could also have a placeholder variable for the class-number, but we
will instead calculate it using argmax. Note that this is a TensorFlow
operator so nothing is calculated at this point.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{y\PYZus{}true\PYZus{}cls} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{dimension}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:tensorflow:From <ipython-input-18-71ccadb4572d>:1: calling argmax (from tensorflow.python.ops.math\_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead

    \end{Verbatim}

    \subsubsection{Convolutional Layer 1}\label{convolutional-layer-1}

We'll now create the first convolutional layer. It takes x\_image as
input and creates num\_filters1 different filters, each having width and
height equal to filter\_size1. Finally we wish to down-sample the image
so it is half the size by using 2x2 max-pooling.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{layer\PYZus{}conv1}\PY{p}{,} \PY{n}{weights\PYZus{}conv1} \PY{o}{=} \PYZbs{}
             \PY{n}{new\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n+nb}{input}\PY{o}{=}\PY{n}{x\PYZus{}image}\PY{p}{,}
                            \PY{n}{num\PYZus{}input\PYZus{}channels}\PY{o}{=}\PY{n}{num\PYZus{}channels}\PY{p}{,}
                            \PY{n}{filter\PYZus{}size}\PY{o}{=}\PY{n}{filter\PYZus{}size1}\PY{p}{,}
                            \PY{n}{num\PYZus{}filters}\PY{o}{=}\PY{n}{num\PYZus{}filters1}\PY{p}{,}
                            \PY{n}{use\PYZus{}pooling}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    The shape of the tensor that will be output by the convolutional layer
is (?, 14, 14, 16) which means that there is an arbitrary number of
images (this is the ?), each image is 14 pixels wide and 14 pixels high,
and there are 16 different channels, one channel for each of the
filters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{layer\PYZus{}conv1}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}20}]:} <tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>
\end{Verbatim}
            
    \subsubsection{Convolutional Layer 2}\label{convolutional-layer-2}

We create the second convolutional layer, which takes as input the
output from the first convolutional layer. The number of input channels
corresponds to the number of filters in the first convolutional layer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{layer\PYZus{}conv2}\PY{p}{,} \PY{n}{weights\PYZus{}conv2} \PY{o}{=} \PYZbs{}
             \PY{n}{new\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n+nb}{input}\PY{o}{=}\PY{n}{layer\PYZus{}conv1}\PY{p}{,}
                            \PY{n}{num\PYZus{}input\PYZus{}channels}\PY{o}{=}\PY{n}{num\PYZus{}filters1}\PY{p}{,}
                            \PY{n}{filter\PYZus{}size}\PY{o}{=}\PY{n}{filter\PYZus{}size2}\PY{p}{,}
                            \PY{n}{num\PYZus{}filters}\PY{o}{=}\PY{n}{num\PYZus{}filters2}\PY{p}{,}
                            \PY{n}{use\PYZus{}pooling}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    The shape is (?, 7, 7, 36).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{layer\PYZus{}conv2}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:} <tf.Tensor 'Relu\_1:0' shape=(?, 7, 7, 36) dtype=float32>
\end{Verbatim}
            
    \subsubsection{Flatten Layer}\label{flatten-layer}

As said before, the convolutional layers output 4-dim tensors. We now
wish to use these as input in a fully-connected network, which requires
for the tensors to be reshaped or flattened to 2-dim tensors.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{layer\PYZus{}flat}\PY{p}{,} \PY{n}{num\PYZus{}features} \PY{o}{=} \PY{n}{flatten\PYZus{}layer}\PY{p}{(}\PY{n}{layer\PYZus{}conv2}\PY{p}{)}
\end{Verbatim}


    The tensors now have shape (?, 1764) which means there's an arbitrary
number of images which have been flattened to vectors of length 1764
each.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{n}{layer\PYZus{}flat}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}24}]:} <tf.Tensor 'Reshape\_1:0' shape=(?, 1764) dtype=float32>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{num\PYZus{}features}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}25}]:} 1764
\end{Verbatim}
            
    \subsubsection{Fully-Connected Layer 1}\label{fully-connected-layer-1}

This code adds a fully-connected layer to the network. The input is the
flattened layer from the previous convolution. The number of neurons or
nodes in the fully-connected layer is fc\_size. ReLU is used so we can
learn non-linear relations.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{n}{layer\PYZus{}fc1} \PY{o}{=} \PY{n}{new\PYZus{}fc\PYZus{}layer}\PY{p}{(}\PY{n+nb}{input}\PY{o}{=}\PY{n}{layer\PYZus{}flat}\PY{p}{,}
                                  \PY{n}{num\PYZus{}inputs}\PY{o}{=}\PY{n}{num\PYZus{}features}\PY{p}{,}
                                  \PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{n}{fc\PYZus{}size}\PY{p}{,}
                                  \PY{n}{use\PYZus{}relu}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    The output of the fully-connected layer is a tensor with shape (?, 128)
where the ? means there is an arbitrary number of images and fc\_size ==
128.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{layer\PYZus{}fc1}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:} <tf.Tensor 'Relu\_2:0' shape=(?, 128) dtype=float32>
\end{Verbatim}
            
    \subsubsection{Fully-Connected Layer 2}\label{fully-connected-layer-2}

This adds another fully-connected layer that outputs vectors of length
10 for determining which of the 10 classes the input image belongs to.
Note that ReLU is not used in this layer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{layer\PYZus{}fc2} \PY{o}{=} \PY{n}{new\PYZus{}fc\PYZus{}layer}\PY{p}{(}\PY{n+nb}{input}\PY{o}{=}\PY{n}{layer\PYZus{}fc1}\PY{p}{,}
                                  \PY{n}{num\PYZus{}inputs}\PY{o}{=}\PY{n}{fc\PYZus{}size}\PY{p}{,}
                                  \PY{n}{num\PYZus{}outputs}\PY{o}{=}\PY{n}{num\PYZus{}classes}\PY{p}{,}
                                  \PY{n}{use\PYZus{}relu}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{layer\PYZus{}fc2}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}29}]:} <tf.Tensor 'add\_3:0' shape=(?, 10) dtype=float32>
\end{Verbatim}
            
    \subsubsection{Predicted Class}\label{predicted-class}

The second fully-connected layer estimates how likely it is that the
input image belongs to each of the 10 classes. However, these estimates
are a bit rough and difficult to interpret because the numbers may be
very small or large, so we want to normalize them so that each element
is limited between zero and one and the 10 elements sum to one. This is
calculated using the so-called softmax function and the result is stored
in y\_pred.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{softmax}\PY{p}{(}\PY{n}{layer\PYZus{}fc2}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} the class\PYZhy{}number is the index of the largest element}
         \PY{n}{y\PYZus{}pred\PYZus{}cls} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{dimension}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Cost-function to be
optimized}\label{cost-function-to-be-optimized}

As in the previous notebook, we use the built-in function for
calculating \emph{cross-entropy}. Note that the function calculates the
softmax internally so we must use the output of layer\_fc2 directly
rather than y\_pred which has already had the softmax applied.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{n}{cross\PYZus{}entropy} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{softmax\PYZus{}cross\PYZus{}entropy\PYZus{}with\PYZus{}logits}\PY{p}{(}\PY{n}{logits}\PY{o}{=}\PY{n}{layer\PYZus{}fc2}\PY{p}{,} \PY{n}{labels}\PY{o}{=}\PY{n}{y\PYZus{}true}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:tensorflow:From <ipython-input-31-00a8cd8b73b9>:1: softmax\_cross\_entropy\_with\_logits (from tensorflow.python.ops.nn\_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See @\{tf.nn.softmax\_cross\_entropy\_with\_logits\_v2\}.


    \end{Verbatim}

    In order to use the cross-entropy to guide the optimization of the
model's variables we need a single scalar value, so we simply take the
average of the cross-entropy for all the image classifications.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{n}{cost} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{cross\PYZus{}entropy}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Optimization Method}\label{optimization-method}

Now that we have a cost measure that must be minimized, we can then
create an optimizer. In this case it is the \textbf{AdamOptimizer} which
is an advanced form of Gradient Descent.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{n}{optimizer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{)}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n}{cost}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Performance Measures}\label{performance-measures}

We need a few more performance measures to display the progress to the
user.

This is a vector of booleans whether the predicted class equals the true
class of each image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{n}{correct\PYZus{}prediction} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{equal}\PY{p}{(}\PY{n}{y\PYZus{}pred\PYZus{}cls}\PY{p}{,} \PY{n}{y\PYZus{}true\PYZus{}cls}\PY{p}{)}
\end{Verbatim}


    This calculates the classification accuracy by first type-casting the
vector of booleans to floats, so that False becomes 0 and True becomes
1, and then calculating the average of these numbers.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{accuracy} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{cast}\PY{p}{(}\PY{n}{correct\PYZus{}prediction}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsection{TensorFlow Run}\label{tensorflow-run}

    Once the \(TensorFlow\) graph has been created, we have to create a
\(TensorFlow\) session which is used to execute the graph. The variables
for weights and biases must also be initialized before we start
optimizing them.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{n}{session} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)}
         \PY{n}{session}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{initialize\PYZus{}all\PYZus{}variables}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:tensorflow:From /Users/jacobjohn/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf\_should\_use.py:118: initialize\_all\_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global\_variables\_initializer` instead.

    \end{Verbatim}

    \subsubsection{Helper-function to perform optimization
iterations}\label{helper-function-to-perform-optimization-iterations}

There are 55000 images in the training-set. It takes a long time to
calculate the gradient of the model using all these images. We therefore
only use a small batch of images in each iteration of the optimizer.
This is also done to avoid running out of memory.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{train\PYZus{}batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{64}
\end{Verbatim}


    This function performs a number of optimization iterations to gradually
improve the variables of the network layers. In each iteration, a new
batch of data is selected from the training-set and then \(TensorFlow\)
executes the optimizer using those training samples. The progress is
printed every 100 iterations.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{c+c1}{\PYZsh{} Counter for total number of iterations performed so far.}
         \PY{n}{total\PYZus{}iterations} \PY{o}{=} \PY{l+m+mi}{0}
         
         \PY{k}{def} \PY{n+nf}{optimize}\PY{p}{(}\PY{n}{num\PYZus{}iterations}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Ensure we update the global variable rather than a local copy.}
             \PY{k}{global} \PY{n}{total\PYZus{}iterations}
             \PY{c+c1}{\PYZsh{} Start\PYZhy{}time used for printing time\PYZhy{}usage below.}
             \PY{n}{start\PYZus{}time} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{total\PYZus{}iterations}\PY{p}{,}
                            \PY{n}{total\PYZus{}iterations} \PY{o}{+} \PY{n}{num\PYZus{}iterations}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} Get a batch of training examples.}
                 \PY{n}{x\PYZus{}batch}\PY{p}{,} \PY{n}{y\PYZus{}true\PYZus{}batch} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{next\PYZus{}batch}\PY{p}{(}\PY{n}{train\PYZus{}batch\PYZus{}size}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{} Put the batch into a dict with the proper names}
                 \PY{n}{feed\PYZus{}dict\PYZus{}train} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{x}\PY{p}{:} \PY{n}{x\PYZus{}batch}\PY{p}{,}
                                    \PY{n}{y\PYZus{}true}\PY{p}{:} \PY{n}{y\PYZus{}true\PYZus{}batch}\PY{p}{\PYZcb{}}
                 \PY{c+c1}{\PYZsh{} Run the optimizer using this batch of training data.}
                 \PY{n}{session}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{optimizer}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{n}{feed\PYZus{}dict\PYZus{}train}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{} Print status every 100 iterations.}
                 \PY{k}{if} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{l+m+mi}{100} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                     \PY{n}{acc} \PY{o}{=} \PY{n}{session}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{accuracy}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{n}{feed\PYZus{}dict\PYZus{}train}\PY{p}{)}
                     \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Optimization Iteration: }\PY{l+s+si}{\PYZob{}0:\PYZgt{}6\PYZcb{}}\PY{l+s+s2}{, Training Accuracy: }\PY{l+s+si}{\PYZob{}1:\PYZgt{}6.1\PYZpc{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{acc}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Update the total number of iterations performed.}
             \PY{n}{total\PYZus{}iterations} \PY{o}{+}\PY{o}{=} \PY{n}{num\PYZus{}iterations}
             
             \PY{n}{end\PYZus{}time} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Difference between start and end\PYZhy{}times.}
             \PY{n}{time\PYZus{}dif} \PY{o}{=} \PY{n}{end\PYZus{}time} \PY{o}{\PYZhy{}} \PY{n}{start\PYZus{}time}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Time usage: }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{timedelta}\PY{p}{(}\PY{n}{seconds}\PY{o}{=}\PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{time\PYZus{}dif}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Helper-function for showing the
performance}\label{helper-function-for-showing-the-performance}

This function prints the classification accuracy on the test-set. It
will also print example errors and confusion matrix if asked.

It takes a while to compute the classification for all the images in the
test-set, that's why the results are re-used by calling the above
functions directly from this function, so the classifications don't have
to be recalculated by each function. Note that this function can use a
lot of computer memory, so it has a parameter to specify a batch size.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{k}{def} \PY{n+nf}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{n}{show\PYZus{}example\PYZus{}errors}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{show\PYZus{}confusion\PYZus{}matrix}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:} 
             \PY{n}{u}\PY{o}{.}\PY{n}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{n}{session}\PY{o}{=}\PY{n}{session}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{x}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{o}{=}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred\PYZus{}cls}\PY{o}{=}\PY{n}{y\PYZus{}pred\PYZus{}cls}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{o}{=}\PY{n}{num\PYZus{}classes}\PY{p}{,} 
                                   \PY{n}{show\PYZus{}example\PYZus{}errors}\PY{o}{=}\PY{n}{show\PYZus{}example\PYZus{}errors}\PY{p}{,} \PY{n}{show\PYZus{}confusion\PYZus{}matrix}\PY{o}{=}\PY{n}{show\PYZus{}confusion\PYZus{}matrix}\PY{p}{)}
\end{Verbatim}


    \subsection{Performance before and after
learning}\label{performance-before-and-after-learning}

As we did with the previous notebook, we'll calculate the accuracy on
the test-set at various points, increasing the iterations of
optimization in between. At this point it is very low because the model
variables have only been initialized and not optimized at all, so it
just classifies the images randomly.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{n}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy on Test-Set: 9.8\% (978 / 10000)

    \end{Verbatim}

    \subsubsection{Performance after 1 optimization
iteration}\label{performance-after-1-optimization-iteration}

The classification accuracy does not improve much from just 1
optimization iteration, because the learning-rate for the optimizer is
set very low, unlike the previous notebook, where it jumps to 40\%.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{n}{optimize}\PY{p}{(}\PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Optimization Iteration:      1, Training Accuracy:   6.2\%
Time usage: 0:00:00
Accuracy on Test-Set: 10.0\% (997 / 10000)

    \end{Verbatim}

    \subsubsection{Performance after 100 optimization
iterations}\label{performance-after-100-optimization-iterations}

After 100 optimization iterations the model has significantly improved
its classification accuracy.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{c+c1}{\PYZsh{} We already performed 1 iteration above.}
         \PY{n}{optimize}\PY{p}{(}\PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{99}\PY{p}{)}
         \PY{n}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{n}{show\PYZus{}example\PYZus{}errors}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Time usage: 0:00:07
Accuracy on Test-Set: 74.0\% (7401 / 10000)
Example errors:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_81_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Performance after 1000 optimization
iterations}\label{performance-after-1000-optimization-iterations}

After 1000 optimization iterations the model has greatly increased its
accuracy on the test-set to more than 90\%.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{c+c1}{\PYZsh{} We performed 100 iterations above.}
         \PY{n}{optimize}\PY{p}{(}\PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{900}\PY{p}{)}
         \PY{n}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{n}{show\PYZus{}example\PYZus{}errors}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Optimization Iteration:    101, Training Accuracy:  73.4\%
Optimization Iteration:    201, Training Accuracy:  78.1\%
Optimization Iteration:    301, Training Accuracy:  71.9\%
Optimization Iteration:    401, Training Accuracy:  82.8\%
Optimization Iteration:    501, Training Accuracy:  87.5\%
Optimization Iteration:    601, Training Accuracy:  93.8\%
Optimization Iteration:    701, Training Accuracy:  89.1\%
Optimization Iteration:    801, Training Accuracy:  92.2\%
Optimization Iteration:    901, Training Accuracy:  85.9\%
Time usage: 0:01:26
Accuracy on Test-Set: 92.7\% (9272 / 10000)
Example errors:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_83_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Performance after 10000 optimization
iterations}\label{performance-after-10000-optimization-iterations}

After 10000 optimization iterations the model has a classification
accuracy on the test-set of about 99\%.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{optimize}\PY{p}{(}\PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{9000}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Optimization Iteration:    101, Training Accuracy:  78.1\%
Optimization Iteration:    201, Training Accuracy:  78.1\%
Optimization Iteration:    301, Training Accuracy:  81.2\%
Optimization Iteration:    401, Training Accuracy:  90.6\%
Optimization Iteration:    501, Training Accuracy:  95.3\%
Optimization Iteration:    601, Training Accuracy:  90.6\%
Optimization Iteration:    701, Training Accuracy:  92.2\%
Optimization Iteration:    801, Training Accuracy:  90.6\%
Optimization Iteration:    901, Training Accuracy:  95.3\%
Optimization Iteration:   1001, Training Accuracy:  92.2\%
Optimization Iteration:   1101, Training Accuracy:  96.9\%
Optimization Iteration:   1201, Training Accuracy:  90.6\%
Optimization Iteration:   1301, Training Accuracy:  96.9\%
Optimization Iteration:   1401, Training Accuracy:  96.9\%
Optimization Iteration:   1501, Training Accuracy: 100.0\%
Optimization Iteration:   1601, Training Accuracy:  96.9\%
Optimization Iteration:   1701, Training Accuracy:  93.8\%
Optimization Iteration:   1801, Training Accuracy:  93.8\%
Optimization Iteration:   1901, Training Accuracy:  92.2\%
Optimization Iteration:   2001, Training Accuracy:  90.6\%
Optimization Iteration:   2101, Training Accuracy:  93.8\%
Optimization Iteration:   2201, Training Accuracy:  93.8\%
Optimization Iteration:   2301, Training Accuracy:  96.9\%
Optimization Iteration:   2401, Training Accuracy:  93.8\%
Optimization Iteration:   2501, Training Accuracy:  96.9\%
Optimization Iteration:   2601, Training Accuracy:  96.9\%
Optimization Iteration:   2701, Training Accuracy:  98.4\%
Optimization Iteration:   2801, Training Accuracy:  93.8\%
Optimization Iteration:   2901, Training Accuracy: 100.0\%
Optimization Iteration:   3001, Training Accuracy:  96.9\%
Optimization Iteration:   3101, Training Accuracy:  98.4\%
Optimization Iteration:   3201, Training Accuracy:  96.9\%
Optimization Iteration:   3301, Training Accuracy:  98.4\%
Optimization Iteration:   3401, Training Accuracy:  96.9\%
Optimization Iteration:   3501, Training Accuracy:  98.4\%
Optimization Iteration:   3601, Training Accuracy:  95.3\%
Optimization Iteration:   3701, Training Accuracy: 100.0\%
Optimization Iteration:   3801, Training Accuracy:  95.3\%
Optimization Iteration:   3901, Training Accuracy:  98.4\%
Optimization Iteration:   4001, Training Accuracy:  98.4\%
Optimization Iteration:   4101, Training Accuracy:  98.4\%
Optimization Iteration:   4201, Training Accuracy:  96.9\%
Optimization Iteration:   4301, Training Accuracy: 100.0\%
Optimization Iteration:   4401, Training Accuracy:  98.4\%
Optimization Iteration:   4501, Training Accuracy:  96.9\%
Optimization Iteration:   4601, Training Accuracy: 100.0\%
Optimization Iteration:   4701, Training Accuracy:  96.9\%
Optimization Iteration:   4801, Training Accuracy:  93.8\%
Optimization Iteration:   4901, Training Accuracy:  96.9\%
Optimization Iteration:   5001, Training Accuracy: 100.0\%
Optimization Iteration:   5101, Training Accuracy:  96.9\%
Optimization Iteration:   5201, Training Accuracy: 100.0\%
Optimization Iteration:   5301, Training Accuracy:  98.4\%
Optimization Iteration:   5401, Training Accuracy:  98.4\%
Optimization Iteration:   5501, Training Accuracy:  98.4\%
Optimization Iteration:   5601, Training Accuracy:  90.6\%
Optimization Iteration:   5701, Training Accuracy: 100.0\%
Optimization Iteration:   5801, Training Accuracy:  95.3\%
Optimization Iteration:   5901, Training Accuracy:  96.9\%
Optimization Iteration:   6001, Training Accuracy:  98.4\%
Optimization Iteration:   6101, Training Accuracy:  98.4\%
Optimization Iteration:   6201, Training Accuracy:  98.4\%
Optimization Iteration:   6301, Training Accuracy:  98.4\%
Optimization Iteration:   6401, Training Accuracy: 100.0\%
Optimization Iteration:   6501, Training Accuracy:  98.4\%
Optimization Iteration:   6601, Training Accuracy:  93.8\%
Optimization Iteration:   6701, Training Accuracy: 100.0\%
Optimization Iteration:   6801, Training Accuracy:  98.4\%
Optimization Iteration:   6901, Training Accuracy:  95.3\%
Optimization Iteration:   7001, Training Accuracy: 100.0\%
Optimization Iteration:   7101, Training Accuracy:  96.9\%
Optimization Iteration:   7201, Training Accuracy: 100.0\%
Optimization Iteration:   7301, Training Accuracy:  98.4\%
Optimization Iteration:   7401, Training Accuracy:  98.4\%
Optimization Iteration:   7501, Training Accuracy: 100.0\%
Optimization Iteration:   7601, Training Accuracy:  98.4\%
Optimization Iteration:   7701, Training Accuracy: 100.0\%
Optimization Iteration:   7801, Training Accuracy: 100.0\%
Optimization Iteration:   7901, Training Accuracy:  98.4\%
Optimization Iteration:   8001, Training Accuracy:  96.9\%
Optimization Iteration:   8101, Training Accuracy:  96.9\%
Optimization Iteration:   8201, Training Accuracy: 100.0\%
Optimization Iteration:   8301, Training Accuracy: 100.0\%
Optimization Iteration:   8401, Training Accuracy:  98.4\%
Optimization Iteration:   8501, Training Accuracy:  98.4\%
Optimization Iteration:   8601, Training Accuracy: 100.0\%
Optimization Iteration:   8701, Training Accuracy:  96.9\%
Optimization Iteration:   8801, Training Accuracy:  98.4\%
Optimization Iteration:   8901, Training Accuracy: 100.0\%
Optimization Iteration:   9001, Training Accuracy: 100.0\%
Time usage: 0:14:42

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{n}{print\PYZus{}test\PYZus{}accuracy}\PY{p}{(}\PY{n}{show\PYZus{}example\PYZus{}errors}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{show\PYZus{}confusion\PYZus{}matrix}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy on Test-Set: 98.5\% (9850 / 10000)
Example errors:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_86_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Confusion Matrix:
[[ 970    0    1    0    0    3    2    1    3    0]
 [   0 1123    5    0    0    1    1    1    4    0]
 [   0    1 1025    2    0    0    0    3    1    0]
 [   0    0    0 1006    0    1    0    0    3    0]
 [   0    0    2    0  971    0    1    2    2    4]
 [   1    0    0   12    0  875    1    1    1    1]
 [   4    2    0    1    1    5  944    0    1    0]
 [   0    1    9    5    0    0    0 1011    1    1]
 [   2    0    5   11    1    2    0    3  948    2]
 [   3    3    1    8    5    3    0    6    3  977]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_86_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Visualization of Weights and
Layers}\label{visualization-of-weights-and-layers}

In trying to understand why the convolutional neural network can
recognize handwritten digits, we will now visualize the weights of the
convolutional filters and the resulting output images.

\subsubsection{Helper-function for plotting convolutional
weights}\label{helper-function-for-plotting-convolutional-weights}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}conv\PYZus{}weights}\PY{p}{(}\PY{n}{weights}\PY{p}{,} \PY{n}{input\PYZus{}channel}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
             \PY{n}{u}\PY{o}{.}\PY{n}{plot\PYZus{}conv\PYZus{}weights}\PY{p}{(}\PY{n}{session}\PY{o}{=}\PY{n}{session}\PY{p}{,} \PY{n}{weights}\PY{o}{=}\PY{n}{weights}\PY{p}{,} \PY{n}{input\PYZus{}channel}\PY{o}{=}\PY{n}{input\PYZus{}channel}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Helper-function for plotting the output of a
convolutional
layer}\label{helper-function-for-plotting-the-output-of-a-convolutional-layer}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n}{layer}\PY{p}{,} \PY{n}{image}\PY{p}{)}\PY{p}{:}
             \PY{n}{u}\PY{o}{.}\PY{n}{plot\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n}{session}\PY{o}{=}\PY{n}{session}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{x}\PY{p}{,} \PY{n}{layer}\PY{o}{=}\PY{n}{layer}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Helper-function for plotting an image with nearest
interpolation.}\label{helper-function-for-plotting-an-image-with-nearest-interpolation.}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{p}{:}
             \PY{n}{u}\PY{o}{.}\PY{n}{plot\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,} \PY{n}{img\PYZus{}shape}\PY{o}{=}\PY{n}{img\PYZus{}shape}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Input image}\label{input-image}

We'll now plot an image from the test set to see how it changes between
the varous layers.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{n}{image1} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{test}\PY{o}{.}\PY{n}{images}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{plot\PYZus{}image}\PY{p}{(}\PY{n}{image1}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_94_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Convolution layer 1}\label{convolution-layer-1}

This is the first randomly generated convolution layer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{n}{plot\PYZus{}conv\PYZus{}weights}\PY{p}{(}\PY{n}{weights}\PY{o}{=}\PY{n}{weights\PYZus{}conv1}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_96_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Applying each of these convolutional filters to the first input image
gives the following output images, which are then used as input to the
second convolutional layer. Note that these images are down-sampled to
14 x 14 pixels which is half the resolution of the original input image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{n}{plot\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n}{layer}\PY{o}{=}\PY{n}{layer\PYZus{}conv1}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image1}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_98_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Convolution Layer 2}\label{convolution-layer-2}

Now we plot the filter-weights for the second convolutional layer.

There are 16 output channels from the first conv-layer, which means
there are 16 input channels to the second conv-layer. The second
conv-layer has a set of filter-weights for each of its input channels.
We start by plotting the filter-weigths for the first channel.

Note again that positive weights are red and negative weights are blue.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}52}]:} \PY{n}{plot\PYZus{}conv\PYZus{}weights}\PY{p}{(}\PY{n}{weights}\PY{o}{=}\PY{n}{weights\PYZus{}conv2}\PY{p}{,} \PY{n}{input\PYZus{}channel}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    It can be difficult to understand and keep track of how these filters
are applied because of the high dimensionality.

Applying these convolutional filters to the images that were ouput from
the first conv-layer gives the following images.

Note that these are down-sampled yet again to 7 x 7 pixels which is half
the resolution of the images from the first conv-layer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}53}]:} \PY{n}{plot\PYZus{}conv\PYZus{}layer}\PY{p}{(}\PY{n}{layer}\PY{o}{=}\PY{n}{layer\PYZus{}conv2}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image1}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_102_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    From these images, it looks like the second convolutional layer might
detect lines and patterns in the input images, which are less sensitive
to local variations in the original input images.

These images are then flattened and input to the fully-connected layer.

    We are now done using \(TensorFlow\), so we close the session to release
its resources.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{n}{session}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \subsection{Performance}\label{performance}

Making a comparison with the previous notebook, we notice that the CNN
takes about 15 minutes to complete the 10000 optimizations, while the
simple linear NN takes a few seconds. This is because of the number of
convolutional layers that must be trained.

On the other hand, we see an improvement in accuracy, going from the
92\% of the linear NN to the 98\% of the CNN.

\subsection{Conclusion}\label{conclusion}

We have seen that a Convolutional Neural Network works much better at
recognizing hand-written digits than the simple linear model after the
same number of iterations.

However, the Convolutional Network is also much more complicated to
implement, and it is not obvious from looking at the filter-weights why
it works and why it sometimes fails. We would also like to train the
weights for the convolutional network instead of using random ones, in
order to extract useful features.

There is an easier, higher level, way to program Convolutional Neural
Networks with \(TensorFlow\) using \textbf{PrettyTensor}, but it hides
what's going on behind.

In the next notebook we will show a faster way to implement the same
kind of CNN, also using the \textbf{Saver} included in \(TensorFlow\),
but this time to classify images from the CIFAR dataset instead of
digits.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
